{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyper - 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: ae21b105 to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import source\n",
    "import numpy as np\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing and reshaping datatset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_cv,y_train,y_cv = train_test_split(X_train,y_train,test_size=0.1,stratify=y_train)\n",
    "\n",
    "X_train = X_train.reshape(54000,-1)/255.0\n",
    "X_cv = X_cv.reshape(6000,-1)/255.0\n",
    "X_test = X_test.reshape(10000,-1)/255.0\n",
    "y_train = source.one_hot_numpy(y_train)\n",
    "y_cv = source.one_hot_numpy(y_cv)\n",
    "y_test = source.one_hot_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = [784, 128, 64, 10]\n",
    "activation_sequence =   ['relu', 'relu', 'softmax']\n",
    "optimizer = \"adam\"\n",
    "learning_rate = 1e-3\n",
    "loss = \"cross_entropy\"\n",
    "initialization = \"Xavier\"\n",
    "momentum = 0.95\n",
    "weight_decay = 1e-6\n",
    "beta_rms = 0.95\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.99\n",
    "md1 = source.FeedForwardNeuralNetwork(arch=arch, activation_sequence=activation_sequence, optimizer=optimizer,\n",
    "                                      learning_rate=learning_rate,weight_decay= weight_decay, loss=loss,initialization=initialization,momentum=momentum,beta_rms=beta_rms,\n",
    "                                      beta_1=beta_1,beta_2=beta_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_train = source.Batchloader(X_train, y_train, batch_size=64,shuffle=True)\n",
    "batch_test = source.Batchloader(X_cv, y_cv, batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Joeld\\Desktop\\IITM\\SEM-08\\DA6401 - DEEP LEARNING\\DA6401-A01\\wandb\\run-20250317_110116-j6vbzw9m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/A1_DA6401_DL/Reporter/runs/j6vbzw9m' target=\"_blank\">dulcet-butterfly-496</a></strong> to <a href='https://wandb.ai/A1_DA6401_DL/Reporter' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/A1_DA6401_DL/Reporter' target=\"_blank\">https://wandb.ai/A1_DA6401_DL/Reporter</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/A1_DA6401_DL/Reporter/runs/j6vbzw9m' target=\"_blank\">https://wandb.ai/A1_DA6401_DL/Reporter/runs/j6vbzw9m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 || loss_train : 0.14211435861208083 | loss_test : 0.15981937495172888 || acc_train : 0.9599814814814814 | acc_test : 0.9525 ||\n",
      "Epoch 2 || loss_train : 0.08919049560435206 | loss_test : 0.11473385605382856 || acc_train : 0.974462962962963 | acc_test : 0.9675 ||\n",
      "Epoch 3 || loss_train : 0.06577621705005804 | loss_test : 0.09934628628464812 || acc_train : 0.9804074074074074 | acc_test : 0.9723333333333334 ||\n",
      "Epoch 4 || loss_train : 0.053350674005590154 | loss_test : 0.09654993055073403 || acc_train : 0.982537037037037 | acc_test : 0.9728333333333333 ||\n",
      "Epoch 5 || loss_train : 0.04415030695661414 | loss_test : 0.09610189112413399 || acc_train : 0.9853518518518518 | acc_test : 0.9735 ||\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "run = wandb.init(entity=\"A1_DA6401_DL\", project=\"Reporter\", config={\"opt\" : optimizer, \"loss\": loss,})\n",
    "run.name = f\"Hyper1_num_layers_2_act_relu_opt_{optimizer}_mnist\"\n",
    "for epoch in range(1,epochs+1):\n",
    "    i = 0\n",
    "    for X_, y_ in batch_train:\n",
    "        i += 1\n",
    "        md1.train_step(X_, y_, epoch)\n",
    "\n",
    "    train_pred = md1.forward_call(inputs_=X_train)\n",
    "    test_pred = md1.forward_call(inputs_=X_cv)\n",
    "\n",
    "    loss_train = source.find_loss(y_pred= train_pred, y_true =y_train, loss=\"cross_entropy\")\n",
    "    loss_cv = source.find_loss(y_pred= test_pred, y_true = y_cv, loss = \"cross_entropy\")\n",
    "\n",
    "    train_pred = md1.forward_call(inputs_=X_train,threshold=True)\n",
    "    test_pred = md1.forward_call(inputs_=X_cv,threshold=True)\n",
    "\n",
    "    accuracy_train = source.accuracy(train_pred, y_train)\n",
    "    accuracy_cv = source.accuracy(test_pred,  y_cv)\n",
    "\n",
    "    run.log(data={\"loss_train\" : loss_train, \"loss_cv\" : loss_cv, \"acc_train\" : accuracy_train, \"acc_cv\" : accuracy_cv})\n",
    "    if epoch%1 == 0:\n",
    "        print(F\"Epoch {epoch} || loss_train : {loss_train} | loss_test : {loss_cv} || acc_train : {accuracy_train} | acc_test : {accuracy_cv} ||\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc_cv</td><td>▁▆███</td></tr><tr><td>acc_train</td><td>▁▅▇▇█</td></tr><tr><td>loss_cv</td><td>█▃▁▁▁</td></tr><tr><td>loss_train</td><td>█▄▃▂▁</td></tr><tr><td>test_acc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc_cv</td><td>0.9735</td></tr><tr><td>acc_train</td><td>0.98535</td></tr><tr><td>loss_cv</td><td>0.0961</td></tr><tr><td>loss_train</td><td>0.04415</td></tr><tr><td>test_acc</td><td>0.9722</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hyper1_num_layers_2_act_relu_opt_adam_mnist</strong> at: <a href='https://wandb.ai/A1_DA6401_DL/Reporter/runs/j6vbzw9m' target=\"_blank\">https://wandb.ai/A1_DA6401_DL/Reporter/runs/j6vbzw9m</a><br> View project at: <a href='https://wandb.ai/A1_DA6401_DL/Reporter' target=\"_blank\">https://wandb.ai/A1_DA6401_DL/Reporter</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250317_110116-j6vbzw9m\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_pred = md1.forward_call(inputs_=X_test,threshold=True)\n",
    "\n",
    "y_true_test = np.argmax(y_test, axis=1)\n",
    "y_pred_test = np.argmax(test_pred, axis=1)\n",
    "\n",
    "run.log(data = {\"test_acc\" : source.accuracy(test_pred,y_test)})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyper - 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: ae21b105 to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import source\n",
    "import numpy as np\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing and reshaping datatset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_cv,y_train,y_cv = train_test_split(X_train,y_train,test_size=0.1,stratify=y_train)\n",
    "\n",
    "X_train = X_train.reshape(54000,-1)/255.0\n",
    "X_cv = X_cv.reshape(6000,-1)/255.0\n",
    "X_test = X_test.reshape(10000,-1)/255.0\n",
    "y_train = source.one_hot_numpy(y_train)\n",
    "y_cv = source.one_hot_numpy(y_cv)\n",
    "y_test = source.one_hot_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = [784, 128, 128, 128, 64, 10]\n",
    "activation_sequence =   ['relu', 'relu', \"relu\", \"relu\", 'softmax']\n",
    "optimizer = \"nadam\"\n",
    "learning_rate = 1e-3\n",
    "loss = \"cross_entropy\"\n",
    "initialization = \"Xavier\"\n",
    "momentum = 0.95\n",
    "weight_decay = 5e-4\n",
    "beta_rms = 0.95\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.99\n",
    "md1 = source.FeedForwardNeuralNetwork(arch=arch, activation_sequence=activation_sequence, optimizer=optimizer,\n",
    "                                      learning_rate=learning_rate,weight_decay= weight_decay, loss=loss,initialization=initialization,momentum=momentum,beta_rms=beta_rms,\n",
    "                                      beta_1=beta_1,beta_2=beta_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_train = source.Batchloader(X_train, y_train, batch_size=64,shuffle=True)\n",
    "batch_test = source.Batchloader(X_cv, y_cv, batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "creating run (0.0s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Joeld\\Desktop\\IITM\\SEM-08\\DA6401 - DEEP LEARNING\\DA6401-A01\\wandb\\run-20250317_110737-nn30jzby</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/A1_DA6401_DL/Reporter/runs/nn30jzby' target=\"_blank\">true-cloud-497</a></strong> to <a href='https://wandb.ai/A1_DA6401_DL/Reporter' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/A1_DA6401_DL/Reporter' target=\"_blank\">https://wandb.ai/A1_DA6401_DL/Reporter</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/A1_DA6401_DL/Reporter/runs/nn30jzby' target=\"_blank\">https://wandb.ai/A1_DA6401_DL/Reporter/runs/nn30jzby</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 || loss_train : 0.11557522215831167 | loss_test : 0.12772835127945514 || acc_train : 0.9648888888888889 | acc_test : 0.9608333333333333 ||\n",
      "Epoch 2 || loss_train : 0.07044924231573921 | loss_test : 0.09395070916301794 || acc_train : 0.9779814814814815 | acc_test : 0.9683333333333334 ||\n",
      "Epoch 3 || loss_train : 0.06284942001922222 | loss_test : 0.0937502035837561 || acc_train : 0.9800185185185185 | acc_test : 0.9716666666666667 ||\n",
      "Epoch 4 || loss_train : 0.03937305452088264 | loss_test : 0.07855537358791301 || acc_train : 0.9871481481481481 | acc_test : 0.9765 ||\n",
      "Epoch 5 || loss_train : 0.03649187465209033 | loss_test : 0.08917810296969093 || acc_train : 0.9877222222222222 | acc_test : 0.9763333333333334 ||\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "run = wandb.init(entity=\"A1_DA6401_DL\", project=\"Reporter\", config={\"opt\" : optimizer, \"loss\": loss,})\n",
    "run.name = f\"Hyper2_num_layers_4_act_relu_opt_{optimizer}_weight_decay_{weight_decay}_mnist\"\n",
    "for epoch in range(1,epochs+1):\n",
    "    i = 0\n",
    "    for X_, y_ in batch_train:\n",
    "        i += 1\n",
    "        md1.train_step(X_, y_, epoch)\n",
    "\n",
    "    train_pred = md1.forward_call(inputs_=X_train)\n",
    "    test_pred = md1.forward_call(inputs_=X_cv)\n",
    "\n",
    "    loss_train = source.find_loss(y_pred= train_pred, y_true =y_train, loss=\"cross_entropy\")\n",
    "    loss_cv = source.find_loss(y_pred= test_pred, y_true = y_cv, loss = \"cross_entropy\")\n",
    "\n",
    "    train_pred = md1.forward_call(inputs_=X_train,threshold=True)\n",
    "    test_pred = md1.forward_call(inputs_=X_cv,threshold=True)\n",
    "\n",
    "    accuracy_train = source.accuracy(train_pred, y_train)\n",
    "    accuracy_cv = source.accuracy(test_pred,  y_cv)\n",
    "\n",
    "    run.log(data={\"loss_train\" : loss_train, \"loss_cv\" : loss_cv, \"acc_train\" : accuracy_train, \"acc_cv\" : accuracy_cv})\n",
    "    if epoch%1 == 0:\n",
    "        print(F\"Epoch {epoch} || loss_train : {loss_train} | loss_test : {loss_cv} || acc_train : {accuracy_train} | acc_test : {accuracy_cv} ||\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc_cv</td><td>▁▄▆██</td></tr><tr><td>acc_train</td><td>▁▅▆██</td></tr><tr><td>loss_cv</td><td>█▃▃▁▃</td></tr><tr><td>loss_train</td><td>█▄▃▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc_cv</td><td>0.97633</td></tr><tr><td>acc_train</td><td>0.98772</td></tr><tr><td>loss_cv</td><td>0.08918</td></tr><tr><td>loss_train</td><td>0.03649</td></tr><tr><td>test_acc</td><td>0.9713</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hyper2_num_layers_4_act_relu_opt_nadam_weight_decay_0.0005_mnist</strong> at: <a href='https://wandb.ai/A1_DA6401_DL/Reporter/runs/nn30jzby' target=\"_blank\">https://wandb.ai/A1_DA6401_DL/Reporter/runs/nn30jzby</a><br> View project at: <a href='https://wandb.ai/A1_DA6401_DL/Reporter' target=\"_blank\">https://wandb.ai/A1_DA6401_DL/Reporter</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250317_110737-nn30jzby\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_pred = md1.forward_call(inputs_=X_test,threshold=True)\n",
    "\n",
    "y_true_test = np.argmax(y_test, axis=1)\n",
    "y_pred_test = np.argmax(test_pred, axis=1)\n",
    "\n",
    "run.log(data = {\"test_acc\" : source.accuracy(test_pred,y_test)})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyper 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: ae21b105 to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import source\n",
    "import numpy as np\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing and reshaping datatset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_cv,y_train,y_cv = train_test_split(X_train,y_train,test_size=0.1,stratify=y_train)\n",
    "\n",
    "X_train = X_train.reshape(54000,-1)/255.0\n",
    "X_cv = X_cv.reshape(6000,-1)/255.0\n",
    "X_test = X_test.reshape(10000,-1)/255.0\n",
    "y_train = source.one_hot_numpy(y_train)\n",
    "y_cv = source.one_hot_numpy(y_cv)\n",
    "y_test = source.one_hot_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = [784, 128, 128, 64, 10]\n",
    "activation_sequence =   ['tanh', 'tanh', \"tanh\", 'softmax']\n",
    "optimizer = \"nadam\"\n",
    "learning_rate = 1e-3\n",
    "loss = \"cross_entropy\"\n",
    "initialization = \"Xavier\"\n",
    "momentum = 0.95\n",
    "weight_decay = 1e-4\n",
    "beta_rms = 0.95\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.999\n",
    "md1 = source.FeedForwardNeuralNetwork(arch=arch, activation_sequence=activation_sequence, optimizer=optimizer,\n",
    "                                      learning_rate=learning_rate,weight_decay= weight_decay, loss=loss,initialization=initialization,momentum=momentum,beta_rms=beta_rms,\n",
    "                                      beta_1=beta_1,beta_2=beta_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_train = source.Batchloader(X_train, y_train, batch_size=64,shuffle=True)\n",
    "batch_test = source.Batchloader(X_cv, y_cv, batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Joeld\\Desktop\\IITM\\SEM-08\\DA6401 - DEEP LEARNING\\DA6401-A01\\wandb\\run-20250317_112655-6c1j921a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/A1_DA6401_DL/Reporter/runs/6c1j921a' target=\"_blank\">driven-donkey-500</a></strong> to <a href='https://wandb.ai/A1_DA6401_DL/Reporter' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/A1_DA6401_DL/Reporter' target=\"_blank\">https://wandb.ai/A1_DA6401_DL/Reporter</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/A1_DA6401_DL/Reporter/runs/6c1j921a' target=\"_blank\">https://wandb.ai/A1_DA6401_DL/Reporter/runs/6c1j921a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 || loss_train : 0.14177109551239558 | loss_test : 0.15243421994312098 || acc_train : 0.9592407407407407 | acc_test : 0.9526666666666667 ||\n",
      "Epoch 2 || loss_train : 0.09155018761719622 | loss_test : 0.1078535964319808 || acc_train : 0.9736481481481482 | acc_test : 0.965 ||\n",
      "Epoch 3 || loss_train : 0.06762729439221124 | loss_test : 0.09503991564784948 || acc_train : 0.9797592592592592 | acc_test : 0.969 ||\n",
      "Epoch 4 || loss_train : 0.05300098112931824 | loss_test : 0.0896836260602044 || acc_train : 0.9844259259259259 | acc_test : 0.9713333333333334 ||\n",
      "Epoch 5 || loss_train : 0.03872038739247794 | loss_test : 0.08166193018917839 || acc_train : 0.988462962962963 | acc_test : 0.9756666666666667 ||\n",
      "Epoch 6 || loss_train : 0.03320203914838722 | loss_test : 0.08397437019490599 || acc_train : 0.9897407407407407 | acc_test : 0.9736666666666667 ||\n"
     ]
    }
   ],
   "source": [
    "epochs = 6\n",
    "run = wandb.init(entity=\"A1_DA6401_DL\", project=\"Reporter\", config={\"opt\" : optimizer, \"loss\": loss,})\n",
    "run.name = f\"Hyper3_num_layers_4_act_tanh_opt_{optimizer}_weight_decay_{weight_decay}_epochs_6_mnist\"\n",
    "for epoch in range(1,epochs+1):\n",
    "    i = 0\n",
    "    for X_, y_ in batch_train:\n",
    "        i += 1\n",
    "        md1.train_step(X_, y_, epoch)\n",
    "\n",
    "    train_pred = md1.forward_call(inputs_=X_train)\n",
    "    test_pred = md1.forward_call(inputs_=X_cv)\n",
    "\n",
    "    loss_train = source.find_loss(y_pred= train_pred, y_true =y_train, loss=\"cross_entropy\")\n",
    "    loss_cv = source.find_loss(y_pred= test_pred, y_true = y_cv, loss = \"cross_entropy\")\n",
    "\n",
    "    train_pred = md1.forward_call(inputs_=X_train,threshold=True)\n",
    "    test_pred = md1.forward_call(inputs_=X_cv,threshold=True)\n",
    "\n",
    "    accuracy_train = source.accuracy(train_pred, y_train)\n",
    "    accuracy_cv = source.accuracy(test_pred,  y_cv)\n",
    "\n",
    "    run.log(data={\"loss_train\" : loss_train, \"loss_cv\" : loss_cv, \"acc_train\" : accuracy_train, \"acc_cv\" : accuracy_cv})\n",
    "    if epoch%1 == 0:\n",
    "        print(F\"Epoch {epoch} || loss_train : {loss_train} | loss_test : {loss_cv} || acc_train : {accuracy_train} | acc_test : {accuracy_cv} ||\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc_cv</td><td>▁▅▆▇█▇</td></tr><tr><td>acc_train</td><td>▁▄▆▇██</td></tr><tr><td>loss_cv</td><td>█▄▂▂▁▁</td></tr><tr><td>loss_train</td><td>█▅▃▂▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc_cv</td><td>0.97367</td></tr><tr><td>acc_train</td><td>0.98974</td></tr><tr><td>loss_cv</td><td>0.08397</td></tr><tr><td>loss_train</td><td>0.0332</td></tr><tr><td>test_acc</td><td>0.9736</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hyper3_num_layers_4_act_tanh_opt_nadam_weight_decay_0.0001_epochs_6_mnist</strong> at: <a href='https://wandb.ai/A1_DA6401_DL/Reporter/runs/6c1j921a' target=\"_blank\">https://wandb.ai/A1_DA6401_DL/Reporter/runs/6c1j921a</a><br> View project at: <a href='https://wandb.ai/A1_DA6401_DL/Reporter' target=\"_blank\">https://wandb.ai/A1_DA6401_DL/Reporter</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250317_112655-6c1j921a\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_pred = md1.forward_call(inputs_=X_test,threshold=True)\n",
    "\n",
    "y_true_test = np.argmax(y_test, axis=1)\n",
    "y_pred_test = np.argmax(test_pred, axis=1)\n",
    "\n",
    "run.log(data = {\"test_acc\" : source.accuracy(test_pred,y_test)})\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
